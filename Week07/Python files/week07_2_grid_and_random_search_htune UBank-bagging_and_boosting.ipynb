{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxGJbLsUhuc8"
   },
   "source": [
    "# Week07 - Prediction using Decision Tree (with Hyperparameter Tuning)\n",
    "\n",
    "This census data is just too tough... try using another dataset -- univeral bank????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tuXRZKEYrDa"
   },
   "source": [
    "## Introduction and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q08EVUytY3eh"
   },
   "source": [
    "In this notebook, we will reuse the [UCI's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/census+income) census data.\n",
    "\n",
    "Previously, we modeled this data using k-NN (with a k search from 1 through root N) and an unpruned decision tree. As previously discuss, for this particular context (relatively equal cost/benefits for Fn vs FP, and imbalanced data classes) we argued that f1 was the best metric to maximize. \n",
    "\n",
    "In previous attempts we found a default (note pruned, and no hyperparameter tuning applied) produced an f1 score of approximately .49, while k-NN (with k=?) produced a recall of approimately 0.70 @ k=19 (see a3_template_approach.ipynb and accompaning video) \n",
    "\n",
    "In this notebook, we will explore if we can apply hyperparameter tuning to develop a better performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmYLcm3aY8X5"
   },
   "source": [
    "## Install and import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install xgboost (it's not part of the sklearn package)\n",
    "# !conda install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8zNdljvIhuc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timsmith/opt/miniconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: The current version of XGBoost (10/09/2022) will display a depreciation warning. You can ignore this. This will most likely be addressed in future XGBoost versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGgrXNQPZT3J"
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q3u5LsGyhudA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/timcsmith/MIS536-Public/raw/master/Data/UniversalBank.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aOH_GFGZZFx"
   },
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "OkUM_mnHhudC",
    "outputId": "b4e542fe-5d03-4602-e4d9-06a6d0e7c65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4    1.6          1         0   \n",
      "1   2   45          19      34     90089       3    1.5          1         0   \n",
      "2   3   39          15      11     94720       1    1.0          1         0   \n",
      "3   4   35           9     100     94112       1    2.7          2         0   \n",
      "4   5   35           8      45     91330       4    1.0          2         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n",
      "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
      "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
      "       'CD Account', 'Online', 'CreditCard'],\n",
      "      dtype='object')\n",
      "                ID          Age   Experience       Income      ZIP Code  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000   5000.000000   \n",
      "mean   2500.500000    45.338400    20.104600    73.774200  93152.503000   \n",
      "std    1443.520003    11.463166    11.467954    46.033729   2121.852197   \n",
      "min       1.000000    23.000000    -3.000000     8.000000   9307.000000   \n",
      "25%    1250.750000    35.000000    10.000000    39.000000  91911.000000   \n",
      "50%    2500.500000    45.000000    20.000000    64.000000  93437.000000   \n",
      "75%    3750.250000    55.000000    30.000000    98.000000  94608.000000   \n",
      "max    5000.000000    67.000000    43.000000   224.000000  96651.000000   \n",
      "\n",
      "            Family        CCAvg    Education     Mortgage  Personal Loan  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000   \n",
      "mean      2.396400     1.937938     1.881000    56.498800       0.096000   \n",
      "std       1.147663     1.747659     0.839869   101.713802       0.294621   \n",
      "min       1.000000     0.000000     1.000000     0.000000       0.000000   \n",
      "25%       1.000000     0.700000     1.000000     0.000000       0.000000   \n",
      "50%       2.000000     1.500000     2.000000     0.000000       0.000000   \n",
      "75%       3.000000     2.500000     3.000000   101.000000       0.000000   \n",
      "max       4.000000    10.000000     3.000000   635.000000       1.000000   \n",
      "\n",
      "       Securities Account  CD Account       Online   CreditCard  \n",
      "count         5000.000000  5000.00000  5000.000000  5000.000000  \n",
      "mean             0.104400     0.06040     0.596800     0.294000  \n",
      "std              0.305809     0.23825     0.490589     0.455637  \n",
      "min              0.000000     0.00000     0.000000     0.000000  \n",
      "25%              0.000000     0.00000     0.000000     0.000000  \n",
      "50%              0.000000     0.00000     1.000000     0.000000  \n",
      "75%              0.000000     0.00000     1.000000     1.000000  \n",
      "max              1.000000     1.00000     1.000000     1.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "# read the first row of the dataset \n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiaaNFX2Zf-I"
   },
   "source": [
    "## Clean/transform data (where necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "3JuJlVGDkINJ",
    "outputId": "082781c3-db3c-44e8-a7fd-ba35f35cbbfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on findings from data exploration, we need to clean up colum names, as there are some leading whitespace characters\n",
    "df.columns = [s.strip() for s in df.columns] \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns we are not using as predictors (see previous notebooks -- we are given a subset of input variables to consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID', 'ZIP Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation education categories into dummy vars\n",
    "df['Education'] = df['Education'].astype('category')\n",
    "df = pd.get_dummies(df, prefix_sep='_', drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKY30W1pZxCP"
   },
   "source": [
    "## Split data intro training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "d0fAfB0ThudG",
    "outputId": "47f231af-3781-4603-95b8-d9a1fca0236e"
   },
   "outputs": [],
   "source": [
    "# construct datasets for analysis\n",
    "target = 'Personal Loan'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)\n",
    "X = df[predictors]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "t0DkCAoChudI",
    "outputId": "4f5824b6-d5e0-419c-c916-6be218916af2"
   },
   "outputs": [],
   "source": [
    "# create the training set and the test set \n",
    "train_X, valid_X, train_y, y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2A_u7rQhuc_"
   },
   "source": [
    "## Prediction with Decision Tree (using default parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30gNRdX-qtNT"
   },
   "source": [
    "You can find details about SKLearm's DecisionTree classifier [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbPfUmcEXf6K"
   },
   "source": [
    "Create a decision tree using all of the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UZ60Vn1AhudK"
   },
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntgxBhvJXkjp"
   },
   "source": [
    "Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "xPL4rRlVhudM",
    "outputId": "db26a1f0-23c9-4a02-87c5-34e3dbd71ccf"
   },
   "outputs": [],
   "source": [
    "_ = dtree.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMvD4-9wXy_1"
   },
   "source": [
    "Review of the performance of the model on the validation/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "YAcO31dIX7JE",
    "outputId": "797a7c84-5c1c-4ec8-c75e-12c675ea8061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.87248322147651\n",
      "Accuracy Score:   0.9766666666666667\n",
      "Precision Score:  0.8904109589041096\n",
      "F1 Score:         0.8813559322033899\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with RandomForest (using default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, RandomeForestClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* n_estimators: The number of trees in the forsest\n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is 100.  \n",
    "* max_depth: The maximum depth per tree. \n",
    "    - Deeper trees might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None, which allows the tree to grow without constraint.\n",
    "* remaining tuning parameters similar to DecisionTree and covered last class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = rforest.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rforest.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8523489932885906\n",
      "Accuracy Score:   0.9826666666666667\n",
      "Precision Score:  0.9694656488549618\n",
      "F1 Score:         0.9071428571428571\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with ADABoost (using default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, ADABoostClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None (meaning, the tree can grow to a point where all leaves have 1 observation).\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - Larger learning rates may not converge on a solution.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost = AdaBoostClassifier(random_state=random_seed)\n",
    "\n",
    "# as with most classifiers, you can experiment with the parameter values\n",
    "#aboost = AdaBoostClassifier(random_state=random_seed, base_estimator=DecisionTreeClassifier(max_depth=4, random_state=random_seed))\n",
    "#aboost = AdaBoostClassifier(random_state=random_seed, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = aboost.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = aboost.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.738255033557047\n",
      "Accuracy Score:   0.9646666666666667\n",
      "Precision Score:  0.8870967741935484\n",
      "F1 Score:         0.8058608058608058\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, GradientBoostingClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None (meaning, the tree can grow to a point where all leaves have 1 observation).\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - Larger learning rates may not converge on a solution.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* Other tuning parameters similar to DecisionTree's and were covered last class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gboost.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gboost.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8791946308724832\n",
      "Accuracy Score:   0.9833333333333333\n",
      "Precision Score:  0.9492753623188406\n",
      "F1 Score:         0.9128919860627177\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, XGBoost has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is 6.\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* colsample_bytree: Represents the fraction of columns to be randomly sampled for each tree. \n",
    "    - It might improve overfitting.\n",
    "    - The value must be between 0 and 1. Default is 1.\n",
    "* subsample: Represents the fraction of observations to be sampled for each tree. \n",
    "    - A lower values prevent overfitting but might lead to under-fitting.\n",
    "    - The value must be between 0 and 1. Default is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier(random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:19:45] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_eek2t0c4ro/croots/recipe/xgboost-split_1659548960591/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timsmith/opt/miniconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/timsmith/opt/miniconda3/lib/python3.9/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "_ = xgboost.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost.predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8791946308724832\n",
      "Accuracy Score:   0.9846666666666667\n",
      "Precision Score:  0.9632352941176471\n",
      "F1 Score:         0.9192982456140351\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summarize results    \n",
    "\n",
    "As usual -- in this section you provide a recap your approach, results, and discussion of findings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall scores...\n",
      "Decision Tree:    0.87248322147651\n",
      "Random Forest:    0.8523489932885906\n",
      "Ada Boosted Tree: 0.738255033557047\n",
      "Gradient Tree:    0.8791946308724832\n",
      "XGBoost Tree:     0.8791946308724832\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall scores...\")\n",
    "print(f\"{'Decision Tree:':18}{dtree_recall}\")\n",
    "print(f\"{'Random Forest:':18}{rforest_recall}\")\n",
    "print(f\"{'Ada Boosted Tree:':18}{aboost_recall}\")\n",
    "print(f\"{'Gradient Tree:':18}{gboost_recall}\")\n",
    "print(f\"{'XGBoost Tree:':18}{xgboost}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Class08b-decision_tree_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
